<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Mouse的博客</title>
		<description>记录学习生活工作的点滴</description>
		<link>http://localhost:4000</link>
		<atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>mongodb index</title>
				<description>&lt;h1 id=&quot;kafka&quot;&gt;kafka&lt;/h1&gt;

&lt;p&gt;参考文章： &lt;a href=&quot;https://blog.csdn.net/qq_36042938/article/details/86690188&quot;&gt;https://blog.csdn.net/qq_36042938/article/details/86690188&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000021746086&quot;&gt;https://segmentfault.com/a/1190000021746086&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Docker 启动 zookeeper 和 kafka (注意 如下的 ip 192.168.1.60 需要换成你本地的ip)&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run -d --name zookeeper -p 2181:2181  wurstmeister/zookeeper

docker run -d --name kafka -p 9092:9092 -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 --link zookeeper -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.60(机器IP):9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -t wurstmeister/kafka
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;进入容器&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker exec -it kafka sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;启动消费者进程&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kafka-console-consumer.sh --bootstrap-server 192.168.1.60:9092 --topic kafeidou --from-beginning
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;再开个窗口，执行第2步，再启动生产者进程
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; kafka-console-producer.sh --broker-list 192.168.1.60(机器IP):9092 --topic kafeidou
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;输入消息payload&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;gt;hello
 &amp;gt;
 &amp;gt;
 &amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;广播和单播：&lt;/p&gt;

&lt;p&gt;广播： 多个consumer 使用不同的group。 这样每个group都能获取到所有消息。对应下游不同业务对接同一个上游的场景。&lt;/p&gt;

&lt;p&gt;单播：多个consumer 使用相同的group。 这样每个consumer被分配到不同的消息，加速消费。&lt;/p&gt;

&lt;h2 id=&quot;实际场景&quot;&gt;实际场景&lt;/h2&gt;

&lt;p&gt;当然实际场景会有一些特殊的情况，比如下游部门丢消息了，想让你补发，如果我们用广播模式，那下游那些没想刷数据的部门也会收到消息。这时候“懦弱”的上游只能给每个下游安排一个topic隔离。这样其实是把困难留给了自己，如果某一天下游十七八个部门都要求补发，那这天你就甭干别的事儿了。&lt;/p&gt;

&lt;p&gt;话说回来，消息弄丢了其实是下游部门的问题，得先严格保证事情处理完了之后再ack. 上游只需提供一个根据id的反查接口 和 一个scan的迭代接口方便全量刷新即可。&lt;/p&gt;
</description>
				<pubDate>Wed, 13 Jul 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/07/kafka</link>
				<guid isPermaLink="true">http://localhost:4000/2022/07/kafka</guid>
			</item>
		
			<item>
				<title>mongodb index</title>
				<description>&lt;h1 id=&quot;mongodb-索引&quot;&gt;mongodb 索引&lt;/h1&gt;

&lt;p&gt;通常我们会用 mongodb 来做kv存储。 但是其实也可以用来做关系型数据库，只需要加上索引即可。原理就是 B tree.&lt;/p&gt;

&lt;p&gt;参考文章: &lt;a href=&quot;https://juejin.cn/post/6844903520747929614&quot;&gt;https://juejin.cn/post/6844903520747929614&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://haicoder.net/mongodb/mongodb-index-principle.html&quot;&gt;https://haicoder.net/mongodb/mongodb-index-principle.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/guangyacyb/article/details/104339183&quot;&gt;https://blog.csdn.net/guangyacyb/article/details/104339183&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://mongoing.com/archives/2797&quot;&gt;https://mongoing.com/archives/2797&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以 createIndex单个字段的索引，还能建立联合索引, 1 -1 控制升序和降序&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; db.person.createIndex( {age: 1, name: -1} )  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看索引&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;db.person.getIndexes() 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看query 是否使用索引,  如果是 &lt;a href=&quot;https://docs.mongodb.org/manual/reference/explain-results/#queryplanner&quot;&gt;COLLSCAN&lt;/a&gt; 说明全表扫描， 如果是 IXSCAN ，就是使用了索引&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;db.person.find({age:18}).explain()
db.person.find({age:18}).explain(&quot;executionStats&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
				<pubDate>Tue, 12 Jul 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/07/mongodb-index</link>
				<guid isPermaLink="true">http://localhost:4000/2022/07/mongodb-index</guid>
			</item>
		
			<item>
				<title>flink</title>
				<description>&lt;h1 id=&quot;flink&quot;&gt;Flink&lt;/h1&gt;

&lt;p&gt;官方文档 : &lt;a href=&quot;https://flink.apache.org/&quot;&gt;https://flink.apache.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;参考文章 : &lt;a href=&quot;https://www.jianshu.com/p/d5ccb3aaabc5&quot;&gt;https://www.jianshu.com/p/d5ccb3aaabc5&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在执行引擎这一层，流处理系统与批处理系统最大不同在于节点间的数据传输方式。&lt;strong&gt;对于一个流处理系统，其节点间数据传输的标准模型是：当一条数据被处理完成后，序列化到缓存中，然后立刻通过网络传输到下一个节点，由下一个节点继续处理。&lt;/strong&gt; 而对于一个&lt;strong&gt;批处理系统，其节点间数据传输的标准模型是：当一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满，就持久化到本地硬盘上，当所有数据都被处理完成后，才开始将处理后的数据通过网络传输到下一个节点。&lt;/strong&gt;这两种数据传输模式是两个极端，对应的是流处理系统对低延迟的要求和批处理系统对高吞吐量的要求。Flink的执行引擎采用了一种十分灵活的方式，同时支持了这两种数据传输模型。Flink以固定的缓存块为单位进行网络数据传输，用户可以通过缓存块超时值指定缓存块的传输时机。如果缓存块的超时值为0，则Flink的数据传输方式类似上文所提到流处理系统的标准模型，此时系统可以获得最低的处理延迟。如果缓存块的超时值为无限大，则Flink的数据传输方式类似上文所提到批处理系统的标准模型，此时系统可以获得最高的吞吐量。同时缓存块的超时值也可以设置为0到无限大之间的任意值。缓存块的超时阈值越小，则Flink流处理执行引擎的数据处理延迟越低，但吞吐量也会降低，反之亦然。通过调整缓存块的超时阈值，用户可根据需求灵活地权衡系统延迟和吞吐量。&lt;/p&gt;
&lt;/blockquote&gt;

</description>
				<pubDate>Mon, 11 Jul 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/07/flink</link>
				<guid isPermaLink="true">http://localhost:4000/2022/07/flink</guid>
			</item>
		
			<item>
				<title>git</title>
				<description>&lt;h1 id=&quot;git-批量迁移&quot;&gt;git 批量迁移&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;先找到每个分支最近一次提交的记录， 并按照提交时间排序, tformat 最后会有换行符，比 format好用一些。&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git br -vvr |awk '{print $1}' |xargs -I {} git log {} --pretty=tformat:&quot;%C(cyan)%at %C(cyan)%ad %C(yellow)%h %C(magenta)%d %C(reset)%s %C(green)[%an]&quot;  -1 --date=iso | sort
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;找到最后一行 (如下任1命令)
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 1.awk 'END {print}'

 2.sed -n '$p'

 3.sed '$!N;$!D'

 4.awk '{b=a&quot;\n&quot;$0;a=$0}END{print b}'

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;找到最近一次提交的分支的记录&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git br -vvr |awk '{print $1}' |xargs -I {} git log {} --pretty=tformat:&quot;%C(cyan)%at %C(cyan)%ad %C(yellow)%h %C(magenta)%d %C(reset)%s %C(green)[%an]&quot;  -1 --date=iso | sort|awk 'END {print}' 
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;sed提取出分支&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#获取最近一次提交
	log=$(git br -vvr |awk '{print $1}' |xargs -I {} git log {} --pretty=tformat:&quot;%C(cyan)%at %C(cyan)%ad %C(yellow)%h %C(magenta)%d %C(reset)%s %C(green)[%an]&quot;  -1 --date=iso | sort|awk 'END {print}') 
	#获取分支名
	echo $log
	branchname=$(echo $log |sed 's/.*(\(.*\)).*/\1/' | awk -F',' '{print $NF}' | sed 's/origin\/\(.*\)/\1/') 
    
	echo $branchname
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
				<pubDate>Fri, 08 Jul 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/07/git-clone</link>
				<guid isPermaLink="true">http://localhost:4000/2022/07/git-clone</guid>
			</item>
		
			<item>
				<title>prometheus</title>
				<description>&lt;h1 id=&quot;prometheus&quot;&gt;prometheus&lt;/h1&gt;

&lt;p&gt;参考文章： &lt;a href=&quot;https://www.prometheus.wang/quickstart/why-monitor.html&quot;&gt;https://www.prometheus.wang/quickstart/why-monitor.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://prometheus.io/docs/introduction/overview/&quot;&gt;https://prometheus.io/docs/introduction/overview/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/202207/architecture.png&quot; alt=&quot;&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://yunlzheng.gitbook.io/prometheus-book/part-ii-prometheus-jin-jie/exporter/custom_exporter_with_java/client_library_java&quot;&gt;java client 接入&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;跟 &lt;a href=&quot;/2022/05/monitor&quot;&gt;Statsd&lt;/a&gt; 的区别 :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;statsd是主动udp上报，推的形式. 而prometheus是 提供http接口供 prometheus server pull， 是拉的形式。&lt;/li&gt;
  &lt;li&gt;statsd 协议提供一些常用的metric的类型，通常有timer、counter、gauge和set四种。这样就无需在java client中自行处理&lt;/li&gt;
&lt;/ol&gt;

</description>
				<pubDate>Thu, 07 Jul 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/07/prometheus</link>
				<guid isPermaLink="true">http://localhost:4000/2022/07/prometheus</guid>
			</item>
		
			<item>
				<title>pdfreader</title>
				<description>&lt;h1 id=&quot;pdfbox&quot;&gt;pdfbox&lt;/h1&gt;

&lt;p&gt;添加依赖&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;!-- https://mvnrepository.com/artifact/org.apache.pdfbox/pdfbox --&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.pdfbox&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;pdfbox&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;3.0.0-alpha3&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;遍历文件夹&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; String path = &quot;/path/to/pdf&quot;;		//要遍历的路径
        File file = new File(path);		//获取其file对象
        File[] fs = file.listFiles();	//遍历path下的文件和目录，放在File数组中
        for(File f:fs){					//遍历File[]数组
            if(!f.isDirectory()) {        //若非目录(即文件)，则打印
//                System.out.println(f);
                parse(f);
            }
        }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;逐页读取&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; try {
        PDDocument document = Loader.loadPDF(file);
        if (!document.isEncrypted()) {
            PDFTextStripper stripper = new PDFTextStripper();
            var lastNo = &quot;&quot;;
            var goodOffset = 1;

            for(int i = 1; i&amp;lt;=document.getNumberOfPages(); i ++){
                stripper.setSortByPosition(true);
                stripper.setStartPage(i);
                stripper.setEndPage(i);

                String text = stripper.getText(document);
            }
            
        }
    } catch (IOException e) {
        e.printStackTrace();
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
				<pubDate>Wed, 06 Jul 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/07/pdfreader</link>
				<guid isPermaLink="true">http://localhost:4000/2022/07/pdfreader</guid>
			</item>
		
			<item>
				<title>python docker</title>
				<description>&lt;h1 id=&quot;python-docker&quot;&gt;python docker&lt;/h1&gt;

&lt;p&gt;参考文章： &lt;a href=&quot;https://www.runoob.com/docker/docker-install-python.html&quot;&gt;https://www.runoob.com/docker/docker-install-python.html&lt;/a&gt;&lt;/p&gt;

</description>
				<pubDate>Tue, 05 Jul 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/07/python-docker</link>
				<guid isPermaLink="true">http://localhost:4000/2022/07/python-docker</guid>
			</item>
		
			<item>
				<title>storm</title>
				<description>&lt;h1 id=&quot;storm&quot;&gt;Storm&lt;/h1&gt;

&lt;p&gt;storm是个流数据的处理框架&lt;/p&gt;

&lt;p&gt;写在前面：当然我还是推荐使用&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;com.alibaba.jstorm&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;jstorm-core&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;2.1.1&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;他山之石: &lt;a href=&quot;https://gitee.com/HuQingmiao/storm-demo&quot;&gt;https://gitee.com/HuQingmiao/storm-demo&lt;/a&gt;  直接就能跑起来&lt;/p&gt;

&lt;p&gt;但是因为我维护的还是个老项目，所以必须使用如下依赖&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.storm&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;storm-core&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.2.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;代码仓库：&lt;a href=&quot;https://github.com/gongchangyou/storm-test&quot;&gt;https://github.com/gongchangyou/storm-test&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;注意这是一个maven项目 不是spring项目&lt;/p&gt;

&lt;p&gt;参考文章:  &lt;a href=&quot;https://zhuanlan.zhihu.com/p/140806701&quot;&gt;https://zhuanlan.zhihu.com/p/140806701&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/xuwujing/p/8584684.html&quot;&gt;https://www.cnblogs.com/xuwujing/p/8584684.html&lt;/a&gt;&lt;/p&gt;

</description>
				<pubDate>Mon, 04 Jul 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/07/storm</link>
				<guid isPermaLink="true">http://localhost:4000/2022/07/storm</guid>
			</item>
		
			<item>
				<title>mysql log</title>
				<description>&lt;h1 id=&quot;mysql-log&quot;&gt;mysql log&lt;/h1&gt;

&lt;p&gt;代码仓库： &lt;a href=&quot;https://github.com/gongchangyou/transactional&quot;&gt;https://github.com/gongchangyou/transactional&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果是mybatis plus, 一行搞定
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果是 jpa 。基于 org.springframework.data.repository.CrudRepository;  如何添加日志呢？&lt;/p&gt;

    &lt;p&gt;注意到 JdbcTemplate.execute 方法中有个 logger.isDebugEnabled() 判断
 &lt;img src=&quot;/images/202206/WechatIMG294.png&quot; alt=&quot;&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;那就配置下 logging.level.root 就行&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; logging.level.root=DEBUG
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;如果是mybatis 1.3.1 看到代码没有注入log的地方。只能把断点加到 CachingExecutor.query 方法中 看 boundSql变量了&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/202206/WechatIMG295.png&quot; alt=&quot;&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
</description>
				<pubDate>Thu, 30 Jun 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/06/mysql-log</link>
				<guid isPermaLink="true">http://localhost:4000/2022/06/mysql-log</guid>
			</item>
		
			<item>
				<title>maven settings</title>
				<description>&lt;h1 id=&quot;maven-settings&quot;&gt;maven settings&lt;/h1&gt;

&lt;p&gt;设置 settings.xml&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mvn -s &quot;D:\program\maven-3.6.3\maven3\conf\settings.xml&quot; clean install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;查看当前生效的 settings&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mvn help:effective-settings
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;mvn命令指定 settings&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mvn install --settings c:\user\settings.xml 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
				<pubDate>Wed, 29 Jun 2022 10:25:06 +0800</pubDate>
				<link>http://localhost:4000/2022/06/mvn-settings</link>
				<guid isPermaLink="true">http://localhost:4000/2022/06/mvn-settings</guid>
			</item>
		
	</channel>
</rss>
