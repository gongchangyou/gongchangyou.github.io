---
layout: post
title: "mongodb index"
date: 2022-07-13 10:25:06 +0800
comments: true
category: mysql
tag: [mysql]


---

# kafka

参考文章： [https://blog.csdn.net/qq_36042938/article/details/86690188](https://blog.csdn.net/qq_36042938/article/details/86690188)

[https://segmentfault.com/a/1190000021746086](https://segmentfault.com/a/1190000021746086)



1.  Docker 启动 zookeeper 和 kafka (注意 如下的 ip 192.168.1.60 需要换成你本地的ip)

```
docker run -d --name zookeeper -p 2181:2181  wurstmeister/zookeeper

docker run -d --name kafka -p 9092:9092 -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 --link zookeeper -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.1.60(机器IP):9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -t wurstmeister/kafka
```



2.  进入容器

    ```
    docker exec -it kafka sh
    ```

3.  启动消费者进程

    ```
    kafka-console-consumer.sh --bootstrap-server 192.168.1.60:9092 --topic kafeidou --from-beginning
    ```
4. 再开个窗口，执行第2步，再启动生产者进程
    ```
    kafka-console-producer.sh --broker-list 192.168.1.60(机器IP):9092 --topic kafeidou
    ```

5. 输入消息payload

    ```
    >hello
    >
    >
    >
    ```






广播和单播：

广播： 多个consumer 使用不同的group。 这样每个group都能获取到所有消息。对应下游不同业务对接同一个上游的场景。

单播：多个consumer 使用相同的group。 这样每个consumer被分配到不同的消息，加速消费。



## 实际场景

当然实际场景会有一些特殊的情况，比如下游部门丢消息了，想让你补发，如果我们用广播模式，那下游那些没想刷数据的部门也会收到消息。这时候“懦弱”的上游只能给每个下游安排一个topic隔离。这样其实是把困难留给了自己，如果某一天下游十七八个部门都要求补发，那这天你就甭干别的事儿了。

话说回来，消息弄丢了其实是下游部门的问题，得先严格保证事情处理完了之后再ack. 上游只需提供一个根据id的反查接口 和 一个scan的迭代接口方便全量刷新即可。